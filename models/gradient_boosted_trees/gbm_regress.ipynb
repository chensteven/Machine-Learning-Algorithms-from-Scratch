{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this implementation, we define a custom GradientBoostingRegressor class that takes as input the number of estimators, learning rate, and maximum depth of each decision tree in the ensemble. We initialize the model with an intercept term equal to the mean of the target variable, and then iteratively train decision trees on the residuals of the previous iterations.\n",
    "\n",
    "The fit method trains the model by iteratively fitting decision trees to the negative gradients of the loss function, and updating the residuals using a learning rate. The predict method makes predictions using the final ensemble of decision trees, by summing the predictions of each tree multiplied by the learning rate.\n",
    "\n",
    "Note that this implementation is a simplified version of a GBM, and does not include many of the optimizations and features found in more advanced implementations such as XGBoost or LightGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "class GradientBoostingRegressor:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.estimators = []\n",
    "        self.intercept = np.mean(y) # initial prediction is the mean of the target variable\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.intercept = np.mean(y) # initial prediction is the mean of the target variable\n",
    "        residual = y - self.intercept\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, residual)\n",
    "            prediction = tree.predict(X)\n",
    "            self.estimators.append(tree)\n",
    "            residual -= self.learning_rate * prediction\n",
    "        \n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(X.shape[0]) + self.intercept\n",
    "        for estimator in self.estimators:\n",
    "            y_pred += self.learning_rate * estimator.predict(X)\n",
    "        return y_pred\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
